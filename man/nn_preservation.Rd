% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rnn.R
\name{nn_preservation}
\alias{nn_preservation}
\title{Nearest Neighbor Preservation}
\usage{
nn_preservation(
  Xin,
  Xout,
  k = 15,
  nn_method_in = "nnd",
  metric_in = "l2sqr",
  nn_method_out = "brute",
  metric_out = "l2sqr",
  is_transposed = FALSE,
  n_threads = 0,
  verbose = FALSE,
  ret_extra = FALSE,
  nn_args_in = list(),
  nn_args_out = list()
)
}
\arguments{
\item{Xin}{the input data (usually high-dimensional), a matrix or data frame
with one observation per row, or if \code{is_transposed = TRUE}, one observation
per column.. Alternatively, it can be a pre-computed nearest neighbor
graph. In the latter case, \code{nn_method_in}, \code{metric_in} and \code{nn_args_in} are
ignored. If \code{Xin} is a data-frame, non-numeric columns are ignored.}

\item{Xout}{the output data (usually lower dimensional than \code{Xin}), a matrix
or data frame with one observation per row, or if \code{is_transposed = TRUE},
one observation per column. Alternatively, it can be a pre-computed nearest
neighbor graph. In the latter case, \code{nn_method_out}, \code{metric_out} and
\code{nn_args_out} are ignored. If \code{Xout} is a data-frame, non-numeric columns
are ignored.}

\item{k}{the number of nearest neighbors to find. Can be a numeric vector,
in which case the preservation is calculated for each value separately.}

\item{nn_method_in}{the nearest neighbor method to calculate the neighbors of
\code{Xin}. Can be one of \code{"brute"} (brute force calculation) or \code{"nnd"}, the
nearest neighbor descent method of Dong and co-workers (2011).}

\item{metric_in}{the distance calculation to apply to \code{Xin}. One of
\code{"euclidean"}, \code{"l2sqr"} (squared Euclidean), \code{"cosine"}, \code{"manhattan"},
\code{"correlation"} (1 minus the Pearson correlation), or \code{"hamming"}.}

\item{nn_method_out}{the nearest neighbor method to calculate the neighbors
of \code{Xout}. See \code{nn_method_in} for details.}

\item{metric_out}{the distance metric to apply to \code{Xout}. See \code{metric_in} for
details.}

\item{is_transposed}{if \code{TRUE} then \code{Xin} and \code{Xout} are assumed to have been
passed in transposed format, i.e. with one observation per column.
Otherwise, \code{Xin} and \code{Xout} will be transposed. For large datasets,
transposing can be slow, so if this function will be called multiple times
with the same input data, it is more efficient to transpose the input data
once outside of this function and set \code{is_transposed = TRUE}.}

\item{n_threads}{the maximum number of threads to use.}

\item{verbose}{if \code{TRUE}, log information about the calculation to the
console.}

\item{ret_extra}{if \code{TRUE}, additionally return the nearest neighbor graphs
for \code{Xin} and \code{Xout}.}

\item{nn_args_in}{list of extra arguments to pass to the nearest neighbor
methods, \code{\link[rnndescent:brute_force_knn]{rnndescent::brute_force_knn()}} or \code{\link[rnndescent:nnd_knn]{rnndescent::nnd_knn()}},
depending on the value of \code{nn_method_in}.}

\item{nn_args_out}{list of extra arguments to pass to the nearest neighbor
methods, \code{\link[rnndescent:brute_force_knn]{rnndescent::brute_force_knn()}} or \code{\link[rnndescent:nnd_knn]{rnndescent::nnd_knn()}},
depending on the value of \code{nn_method_out}.}
}
\value{
the mean value of the intersection of the neighborhoods per
observation scaled between \code{0} (no neighbors in common) to \code{1} (all
neighbors in common). For randomly distributed \code{Xout}, the expected
preservation is around \code{1/k} as long as \code{k} is a lot smaller than the
number of observations. If \code{k} is a vector, then the return value is a
vector of the preservations for each \code{k} in the order they were passed. If
\code{ret_extra = TRUE}, then a list is returned containing:
\itemize{
\item \code{nnp}: the vector of nearest neighbor preservation values.
\item \code{nn_in}: the nearest neighbor graph for \code{Xin}. See the
'Nearest Neighbor Graph Format' section for details.
\item \code{nn_out}: the nearest neighbor graph for \code{Xout}. See the
'Nearest Neighbor Graph Format' section for details.
}
}
\description{
Calculates the overlap of two nearest neighbors graphs.
}
\details{
As a measure of local structure preservation, the k-nearest neighbor graph of
the input data, and that of the output data is calculated. For each
observation the number of neighbors in common in each graph is calculated and
the mean value over the entire dataset is reported.

There are two methods for calculating the nearest neighbor graph: a brute
force approach involving calculating all pairs distances or an approximate
nearest neighbors approach using the nearest neighbor descent method of Dong
and co-workers (2011). The brute force approach scales with the square of the
number of observations and is linear in the number of features. The nearest
neighbor descent method is likely to be more economical for high dimensional
input. Because the output data is often low-dimensional (e.g. 2D), brute
force neighbor search is often feasible for \code{Xout} even when it isn't for
\code{Xin}.

For finer control of the nearest neighbor calculations, you can pass extra
arguments to those functions via the \code{nn_args_in} and \code{nn_args_out} lists.
See the documentation for the \code{\link[rnndescent:brute_force_knn]{rnndescent::brute_force_knn()}} and
\code{\link[rnndescent:nnd_knn]{rnndescent::nnd_knn()}} functions for more details.

Because the nearest neighbor search can be time-consuming, if you set
\code{ret_extra = TRUE}, the return value of this function is a list which
includes the nearest neighbor graph for \code{Xin} and for \code{Xout}. The graph can
be passed to \code{Xin} or \code{Xout} and re-used. This is useful if you are comparing
a fixed \code{Xin} with multiple \code{Xout}, e.g. where different dimensionality
reduction methods have been used, or parameters such as output dimensionality
or random number seed have been been modified.
}
\section{Nearest Neighbor Graph Format}{


Rather than provide the observations to \code{Xin} and \code{Xout}, pre-computed
nearest neighbor graphs can be provided. The format of the graph must be a
list containing:
\itemize{
\item \code{idx} a matrix with as many as rows as observations in the input data and
\code{k} columns. The \code{i}th row of this matrix contains the row indices of the
nearest neighbors of observation \code{i} in non-decreasing distance order.
\item \code{dist} (optional) a matrix with the same dimensions as \code{idx}, containing the
equivalent distances. This information is not actually used by the
preservation function but is included in the output of the nearest neighbor
calculation. So if you provide your own nearest neighbor data, this matrix
does not need to be present.
}
}

\examples{
iris_pca <- stats::prcomp(iris[, -5], rank. = 2, scale = FALSE, retx = TRUE)$x
nn_preservation(iris, iris_pca)

# Calculate for multiple values of k
nn_preservation(iris, iris_pca, k = c(15, 30))

# Return the nearest neighbor graphs
res <- nn_preservation(iris, iris_pca, k = c(15, 30), ret_extra = TRUE)

# Re-use the input neighbor graph for these calculations
nn_preservation(res$nn_in, iris_pca, k = c(2, 5, 10), ret_extra = TRUE)

# For small datasets, brute force search is more efficient than nearest
# neighbor descent
nn_preservation(res$nn_in, iris_pca,
  k = c(2, 5, 10), ret_extra = TRUE,
  nn_method_in = "brute"
)
}
\references{
Dong, W., Moses, C., & Li, K. (2011, March).
Efficient k-nearest neighbor graph construction for generic similarity measures.
In \emph{Proceedings of the 20th international conference on World Wide Web}
(pp. 577-586).
ACM.
\url{https://doi.org/10.1145/1963405.1963487}.
}
\seealso{
The \href{https://github.com/jlmelville/rnndescent}{rnndescent} package
and the \code{\link[rnndescent:brute_force_knn]{rnndescent::brute_force_knn()}} and \code{\link[rnndescent:nnd_knn]{rnndescent::nnd_knn()}}
functions.
}
